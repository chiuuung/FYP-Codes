# ğŸ“± NEW Architecture - Streaming Setup

## ğŸ¯ How It Works Now

**Mac/Jetson Side:**
- Webcam captures video
- Python server runs YOLOv8 detection
- Records when cat + human detected
- Streams live feed to network

**iPhone Side:**
- Just a viewer/monitor
- NO camera needed!
- Shows live stream from Mac/Jetson
- Browse and play recorded videos

---

## ğŸš€ Quick Start

### Step 1: Start Streaming Server on Mac

```bash
cd /path/to/hand-pet-interaction-detector

# Stop old server if running
lsof -ti:5001 | xargs kill -9

# Start streaming server
python3 ios_app/streaming_backend_server.py
```

**You should see:**
```
âœ… Model loaded successfully!
ğŸ“¹ Starting camera thread...
âœ… Camera opened: 1280x720

Server URL: http://10.17.94.27:5001
Live Stream: http://10.17.94.27:5001/stream/live
```

### Step 2: Update iOS App in Xcode

**Files to update in your Xcode project:**

1. **Replace `ContentView.swift`**
   - Copy from: `ios_app/ContentView.swift`
   - Changes: Uses `StreamView` instead of `CameraView`

2. **Add `StreamView.swift`** (NEW FILE)
   - Copy from: `ios_app/StreamView.swift`
   - This displays the video stream from Mac/Jetson

3. **Update `NetworkManager.swift`**
   - Copy from: `ios_app/NetworkManager.swift`
   - Added `fetchLiveFrame()` method for streaming

4. **Keep `VideosView.swift`** (no changes)

5. **Can DELETE `CameraView.swift`** (not needed anymore!)

### Step 3: Update Info.plist

**REMOVE camera permission** (not needed anymore!):
- Delete: `Privacy - Camera Usage Description`

**Keep only network permission:**
```xml
<key>NSAppTransportSecurity</key>
<dict>
    <key>NSAllowsArbitraryLoads</key>
    <true/>
</dict>
```

### Step 4: Run iOS App

1. Clean Build: **Shift+Cmd+K**
2. Build and Run: **Cmd+R**
3. In Settings, enter: `http://10.17.94.27:5001`
4. Test connection
5. Go to "Live Stream" tab
6. You should see your Mac's webcam feed!

---

## ğŸ§ª Testing

### Test 1: Server Webcam
On Mac, check if webcam is working:
```bash
# Test camera access
python3 -c "import cv2; cap = cv2.VideoCapture(0); print('Camera OK' if cap.isOpened() else 'Failed'); cap.release()"
```

### Test 2: Stream API
```bash
curl http://localhost:5001/stream/live | jq '.detections'
```

### Test 3: Live Detection
1. Position yourself in front of Mac webcam
2. Open iOS app â†’ Live Stream tab
3. You should see yourself with "human" detection
4. Show a cat picture/video on another screen
5. When both visible â†’ "RECORDING" appears!
6. Check "Recordings" tab for videos

---

## ğŸ“‹ File Structure

```
ios_app/
â”œâ”€â”€ streaming_backend_server.py  â­ ACTIVE - Mac/Jetson server with webcam
â”œâ”€â”€ cleanup_videos.py            ğŸ§¹ NEW - Manual video cleanup utility
â”œâ”€â”€ STREAMING_SETUP.md           ğŸ“– This file
â”œâ”€â”€ StreamView.swift             â­ NEW - iOS stream viewer
â”œâ”€â”€ ContentView.swift            âœï¸  UPDATED - Uses StreamView
â”œâ”€â”€ NetworkManager.swift         âœï¸  UPDATED - Added streaming
â”œâ”€â”€ VideosView.swift             âœ… Video playback view
â””â”€â”€ HandPetDetectorApp.swift     âœ… Main iOS app
```

---

## ğŸ¬ Demo Flow

1. **Start Server**: Mac/Jetson runs with webcam
2. **Open iOS App**: Connect to server
3. **View Stream**: See live feed with detections
4. **Trigger Recording**: Show cat + human to camera
5. **View Recordings**: Browse saved videos in app

---

## ğŸ”§ Configuration

### Change Camera (for Jetson)
In `streaming_backend_server.py`, line 31:
```python
CAMERA_ID = 0  # Change to 1 or 2 for external camera
```

### Adjust Detection & Recording
```python
CONFIDENCE_THRESHOLD = 0.25  # Lower = more detections
COOLDOWN_SECONDS = 2         # Recording timeout
MAX_VIDEOS = 10              # Maximum stored videos (auto-cleanup)
```

### Storage Management

**Auto-Cleanup (Built-in):**
- Automatically keeps only 10 newest videos
- Runs after each recording stops
- Deletes oldest videos first
- No manual intervention needed

**Manual Cleanup (if needed):**
```bash
python3 ios_app/cleanup_videos.py
```

**Recorded videos location:**
```
recorded_videos/interaction_YYYYMMDD_HHMMSS.mp4
```

---

## âœ… Advantages of New Architecture

- âœ… No iPhone camera needed
- âœ… Better for Jetson Nano deployment
- âœ… iPhone is just a remote viewer
- âœ… Can add multiple viewer devices
- âœ… All processing on Mac/Jetson
- âœ… **Auto-storage management** (max 10 videos)
- âœ… Cleaner separation of concerns
- âœ… Easier to deploy and scale
- âœ… Network-based streaming architecture

---

## ğŸš€ Ready to Test!

1. Start server: `python3 ios_app/streaming_backend_server.py`
2. Update Xcode project files
3. Run iOS app
4. See your Mac webcam feed on iPhone!

---

## ESP32-S3 Camera Streaming Setup

1. **Flash your ESP32-S3 with the provided `esp32s3_camera_stream.ino`**
   - Configure your WiFi SSID/password and backend server IP/port in the sketch.
   - The ESP32 will send JPEG frames to the backend at `/esp32/frame` (default 10 FPS).
   - You can preview the stream locally at `http://<esp32-ip>/stream` in a browser.

2. **Start the backend server on your Mac/Jetson**
   - By default, the backend uses the Mac webcam.
   - To switch to ESP32-S3 camera, send:
     ```bash
     curl -X POST http://<backend-ip>:5001/esp32/enable -H "Content-Type: application/json" -d '{"enable": true}'
     ```
   - To switch back to Mac webcam:
     ```bash
     curl -X POST http://<backend-ip>:5001/esp32/enable -H "Content-Type: application/json" -d '{"enable": false}'
     ```

3. **iOS App**
   - No changes needed; it will display whichever source the backend is using.

**Tip:**
- The backend will auto-detect and process whichever camera source is active.
- You can run both ESP32 and Mac webcam, and switch sources as needed for testing or deployment.

---
