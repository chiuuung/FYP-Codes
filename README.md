# ğŸ“ FYP - Human-Cat Interaction Detector (Clean Version)

This is the **organized and ready-to-run** version of the project with all essential components clearly labeled.

---

## ğŸ“‚ Project Structure

```
new FYP/
â”œâ”€â”€ README.md                    # ğŸ‘ˆ You are here
â”œâ”€â”€ AI_Model/                    # ğŸ¤– AI Model & Training
â”‚   â”œâ”€â”€ weights/
â”‚   â”‚   â””â”€â”€ best.pt             # â­ Trained YOLOv8s model (77% mAP50)
â”‚   â”œâ”€â”€ training_scripts/
â”‚   â”‚   â”œâ”€â”€ train_model.py      # Script to train new models
â”‚   â”‚   â””â”€â”€ test_model.py       # Script to test model accuracy
â”‚   â””â”€â”€ requirements.txt         # Python dependencies for AI
â”‚
â”œâ”€â”€ iOS_App/                     # ğŸ“± iOS Application
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ streaming_backend_server.py  # â­ Main server (Mac/Jetson)
â”‚   â”‚   â”œâ”€â”€ cleanup_videos.py            # Video storage management
â”‚   â”‚   â””â”€â”€ start_ios_server.sh          # Quick start script
â”‚   â””â”€â”€ xcode_project/
â”‚       â”œâ”€â”€ StreamView.swift             # Live stream viewer
â”‚       â”œâ”€â”€ ContentView.swift            # Main app view
â”‚       â”œâ”€â”€ NetworkManager.swift         # API communication
â”‚       â”œâ”€â”€ VideosView.swift             # Video playback
â”‚       â””â”€â”€ HandPetDetectorApp.swift     # App entry point
â”‚
â”œâ”€â”€ Dataset/                     # ğŸ“Š Dataset Configuration
â”‚   â”œâ”€â”€ dataset.yaml            # Original dataset config
â”‚   â””â”€â”€ expanded_data.yaml      # Expanded dataset config (2500+ images)
â”‚
â””â”€â”€ Documentation/               # ğŸ“– Project Documentation
    â”œâ”€â”€ README.md               # Main project overview
    â”œâ”€â”€ STREAMING_SETUP.md      # iOS app setup guide
    â””â”€â”€ TRAINING_DOCUMENTATION.md  # Training methodology & results
```

---

## ğŸš€ Quick Start Guide

### **1ï¸âƒ£ Start the Backend Server (Mac/Jetson)**

```bash
cd "/Users/tszchiung/Desktop/new FYP/iOS_App/backend"

# Option A: Use the start script
./start_ios_server.sh

# Option B: Run directly
python3 streaming_backend_server.py
```

**What you should see:**
```
âœ… Model loaded successfully!
ğŸ“¹ Starting camera thread...
âœ… Camera opened: 1280x720

Server URL: http://YOUR_IP:5001
Live Stream: http://YOUR_IP:5001/stream/live
```

### **2ï¸âƒ£ Stop the Server**

```bash
# Press Ctrl+C in the terminal

# OR force kill:
lsof -ti:5001 | xargs kill -9
```

### **3ï¸âƒ£ Run iOS App**

1. Open Xcode
2. Create new iOS project (or use existing)
3. Copy all files from `iOS_App/xcode_project/` to your Xcode project
4. Update `Info.plist`:
   ```xml
   <key>NSAppTransportSecurity</key>
   <dict>
       <key>NSAllowsArbitraryLoads</key>
       <true/>
   </dict>
   ```
5. In app Settings, set server URL: `http://YOUR_MAC_IP:5001`
6. Run on iPhone/iPad

---

## ğŸ¯ Key Features

### âœ… **Auto-Recording**
- Automatically records when **cat AND human** detected together
- 2-second cooldown between recordings
- Videos saved as: `interaction_YYYYMMDD_HHMMSS.mp4`

### âœ… **Auto-Storage Management**
- Keeps only **10 newest videos** automatically
- Older videos deleted after each recording
- Manual cleanup: `python3 cleanup_videos.py`

### âœ… **Live Streaming**
- Real-time webcam feed to iOS devices
- Shows detection confidence levels
- Recording indicator when active

### âœ… **iOS Viewer App**
- **Live Stream** tab: Watch real-time feed
- **Recordings** tab: Browse and play saved videos
- No iPhone camera needed (viewer only)

---

## ğŸ“Š Model Performance

- **Model**: YOLOv8s
- **Dataset**: 2500+ annotated images
- **Overall mAP50**: 77.0%
- **Cat Detection**: 90.4% mAP50
- **Human Detection**: 63.7% mAP50
- **Model Size**: ~22 MB
- **Location**: `AI_Model/weights/best.pt`

---

## ğŸ”§ Configuration

### **Backend Server Settings**
Edit `iOS_App/backend/streaming_backend_server.py`:

```python
# Line 21-25
MODEL_PATH = "../AI_Model/weights/best.pt"  # Update path to model
CAMERA_ID = 0                                # Change for external camera
CONFIDENCE_THRESHOLD = 0.25                  # Detection sensitivity
COOLDOWN_SECONDS = 2                         # Recording timeout
MAX_VIDEOS = 10                              # Max stored videos
```

### **iOS App Settings**
In the app's Settings tab:
- **Server URL**: `http://YOUR_MAC_IP:5001`
- Test connection before viewing stream

---

## ğŸ“– Documentation Files

| File | Purpose |
|------|---------|
| **Documentation/README.md** | Complete project overview |
| **Documentation/STREAMING_SETUP.md** | Detailed iOS app setup |
| **Documentation/TRAINING_DOCUMENTATION.md** | Model training guide |

---

## ğŸ› ï¸ Requirements

### **For Backend (Mac/Jetson)**
```bash
cd AI_Model
pip3 install -r requirements.txt
```

**Key packages:**
- `ultralytics` (YOLOv8)
- `opencv-python` (Camera & video)
- `flask` (Web server)
- `torch` (Deep learning)

### **For iOS App**
- Xcode 14+
- iOS 15+ device/simulator
- Network connectivity to Mac/Jetson

---

## ğŸ¬ Workflow

```
1. Start Backend Server
   â†“
2. Mac/Jetson webcam captures video
   â†“
3. YOLOv8 detects humans & cats
   â†“
4. Auto-records when both detected
   â†“
5. Streams to iOS app
   â†“
6. View live feed & recordings on iPhone
```

---

## ğŸ› Troubleshooting

### **Server won't start**
```bash
# Check if port 5001 is in use
lsof -i :5001

# Kill existing process
lsof -ti:5001 | xargs kill -9
```

### **Model not found**
```bash
# Verify model exists
ls -lh AI_Model/weights/best.pt

# Update MODEL_PATH in streaming_backend_server.py
```

### **iOS app can't connect**
```bash
# Get your Mac's IP address
ipconfig getifaddr en0

# Update server URL in iOS app settings
# Example: http://10.17.94.27:5001
```

### **Camera not working**
```bash
# Test camera access
python3 -c "import cv2; cap = cv2.VideoCapture(0); print('OK' if cap.isOpened() else 'FAILED')"

# Try different camera ID (0, 1, or 2)
```

---

## ğŸ“ Training New Models

See `Documentation/TRAINING_DOCUMENTATION.md` for details.

**Quick training:**
```bash
cd AI_Model/training_scripts

python3 train_model.py \
  --data "../../Dataset/expanded_data.yaml" \
  --epochs 50 \
  --batch-size 8 \
  --model yolov8s
```

---

## âœ… Project Status

- âœ… **AI Model**: Trained and tested (77% mAP50)
- âœ… **Backend Server**: Streaming + Auto-recording working
- âœ… **iOS App**: Live viewer + Video playback complete
- âœ… **Storage**: Auto-cleanup implemented
- â³ **Jetson Nano**: Deployment pending

---

## ğŸ“ Support

For detailed setup instructions, refer to:
- `Documentation/STREAMING_SETUP.md` - iOS app setup
- `Documentation/TRAINING_DOCUMENTATION.md` - Model training
- `Documentation/README.md` - Full project details

---

## ğŸ“ Project Info

**Title**: Human-Cat Interaction Detector with iOS Monitoring  
**Technology**: YOLOv8, Python, Swift, Flask, OpenCV  
**Platform**: Mac/Jetson Nano (Backend) + iOS (Frontend)  
**Architecture**: Client-Server Streaming Model

---

**Ready to run! ğŸš€**
